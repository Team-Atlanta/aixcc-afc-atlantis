# CRS-SARIF
This repository contains all the code related to SARIF, including CRS-SARIF, sarif-generation, sarif-validation, reachability analysis, benchmark creation, and benchmarks, etc...

## Running CRS-SARIF in local
You can test the CRS-SARIF in local by running the unified script.

```bash
python crs_test.py --project-name <project-name> --project-language <project-language> --original-oss-fuzz-dir <original-oss-fuzz-dir> --crs-test-dir <crs-test-dir> --tarball-dir <tarball-dir> --run-docker-build --run-sarif-build --run-crs
```

After running the CRS-SARIF docker, you can test the CRS-SARIF by passing the sarif report using following command.

```bash
python test_crs_sarif.py -s <sarif-report-path>
```

## End-to-End Testing
For comprehensive testing of multiple projects, use the end-to-end test script:

```bash
python e2e_test.py \
    --target-yaml tests/crs-sarif-r3-test-target.yaml \
    --original-oss-fuzz-dir <original-oss-fuzz-dir> \
    --crs-test-dir <crs-test-dir> \
    --tarball-dir <tarball-dir> \
    --run-docker-build \
    --run-sarif-build \
    --run-crs \
    --send-sarif-files
```

### E2E Test Features:
- **Batch Processing**: Test multiple projects defined in a YAML configuration
- **Sequential/Parallel Execution**: Control with `--max-workers` parameter
- **Automatic Port Management**: Each project gets assigned a unique port (starting from 4321)
- **Log Management**: Automatically save CRS container logs to specified directory
- **Selective Testing**: Filter specific projects with `--filter-projects`
- **Failure Handling**: Continue on failures with `--continue-on-failure`
- **Automatic Cleanup**: Clean up Docker resources after each project
- **Comprehensive Reporting**: Detailed success/failure summary with port and log information

### Parallel Execution
To run multiple projects simultaneously:

```bash
python e2e_test.py \
    --target-yaml tests/crs-sarif-r3-test-target.yaml \
    --max-workers 3 \
    --start-port 4321 \
    --log-dir ./project-logs \
    --original-oss-fuzz-dir /path/to/oss-fuzz \
    --crs-test-dir /path/to/crs-test \
    --tarball-dir /path/to/cp_tarballs \
    --run-sarif-build \
    --run-crs \
    --send-sarif-files \
    --save-logs
```

This will process 3 projects concurrently, with each CRS instance running on different ports (4321, 4322, 4323, etc.).

### Log Management
The script automatically saves CRS container logs for each project:

- **Log Directory**: Specify with `--log-dir` (default: `./logs`)
- **Log Files**: Named as `crs-{project-name}-port-{port}.log`
- **Log Content**: Includes container name, port, timestamp, and both stdout/stderr
- **Auto-save**: Enabled by default with `--save-logs` flag

Example log file: `./logs/crs-mock-c-port-4321.log`

### Example: Test with custom log directory
```bash
python e2e_test.py \
    --target-yaml tests/crs-sarif-r3-test-target.yaml \
    --filter-projects "mock-c,mock-java" \
    --log-dir /custom/log/path \
    --original-oss-fuzz-dir /path/to/oss-fuzz \
    --crs-test-dir /path/to/crs-test \
    --tarball-dir /path/to/cp_tarballs \
    --run-sarif-build \
    --run-crs \
    --send-sarif-files
```

## Manual Step-by-Step Testing
If you want to run the CRS-SARIF one by one, you can run the following commands.

1. Build the docker images
```bash
bash ./docker-build.sh
```
2. Build codeql db, joern cpg, and SVF dot, etc in CP-MANAGER
```bash
# Fill the .env file with the correct values
cp .env.sarif_builder .env
python build.py
```
3. Run CRS-SARIF
```bash
# Fill the .env.crs_test file with the correct values
cp .env.crs_sarif .env.crs_test
docker compose up --build
```

4. Test sarif validation
```bash
python test_crs_sarif.py -s <sarif-report-path> -d <crs-sarif-docker-container-id>
```
You can check the docker compose logs and 'sarif_analysis.json' file to see the reachability analysis results.



## Repo Structure
<pre>
üìÇ Project Structure
 ‚îú‚îÄ‚îÄ üìÅ crs_sarif: CRS SARIF using sarif package
 ‚îú‚îÄ‚îÄ üìÅ api: HTTP API tools for communication between VAPI and crs-sarif
 ‚îú‚îÄ‚îÄ üìÅ sarif: Main package. Contains code for generator, validator, reachability analysis, benchmark creation, etc.
 ‚îú‚îÄ‚îÄ üìÅ sast: Static Application Security Testing code for benchmark generation
 ‚îú‚îÄ‚îÄ üìÅ sootup: Sootup code for callgraph generation
 ‚îú‚îÄ‚îÄ üìÅ tracer: Tracer code for getting call traces from seed or pov
 ‚îú‚îÄ‚îÄ üìÅ benchmarks: Benchmarks for SARIF validation generated by SAST

</pre>

## SARIF package
- Main package for SARIF generation and validation
- [docs](./sarif/README.md)

## SAST
- SAST tool execution environment for creating SARIF validation benchmarks
- [docs](./sast/README.md)

## Benchmarks
- Benchmarks for SARIF validation
- SARIF reports generated using `pov to sarif (sarif generator)`, `commercial SAST`, and `custom generation (simple modification based on TP)` methods for all aixcc benchmarks
- TP: `pov to sarif results`
- FP: `all other sarif reports` except those that have the same semantic meaning as TP

## SVF
- SVF without multithreading
```
2025-05-28 21:25:25.138 | INFO     | __main__:log:85 - [SARIF-BUILDER] SVF processing took 831.2479984760284 seconds
```

- SVF with multithreading (worker=4)
```
2025-05-28 22:02:04.526 | INFO     | __main__:log:85 - [SARIF-BUILDER] SVF processing took 221.77592158317566 seconds
```

## Sootup
- Sootup code for callgraph generation
- [docs](./sootup/README.md)

## Tracer
- Tracer code for getting call traces from seed or pov
- [docs](./tracer/README.md)