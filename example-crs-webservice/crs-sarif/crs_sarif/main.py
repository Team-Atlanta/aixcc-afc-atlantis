# generated by fastapi-codegen:
#   filename:  ssapi-swagger.yaml
#   timestamp: 2025-04-09T04:08:41+00:00

from __future__ import annotations

import asyncio
import json
import logging
import os
import typing
from contextlib import asynccontextmanager
from pathlib import Path
import typing

import urllib3
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from openapi_client.models.types_assessment import TypesAssessment
from pydantic import ValidationError

from crs_sarif.models.models import (
    Error,
    PatchMatchRequest,
    POVMatchRequest,
    SARIFMatchRequest,
    PoVSarifMatchRequest,
    PoVSarifMatchResponse,
    PoVPatchSarifMatchRequest,
    PoVPatchSarifMatchResponse,
)
from crs_sarif.services.analyser import AnalyserService
from crs_sarif.services.blobgen import blobgen
from crs_sarif.services.matcher import (
    match_patch,
    match_pov,
    match_sarif,
    match_pov_sarif,
    match_pov_patch_sarif,
)
from crs_sarif.utils.context import CRSEnv
from crs_sarif.utils.dir_setting import CRSDirSetting
from crs_sarif.utils.redis_util import RedisUtil
from crs_sarif.utils.vapi_client import VapiClient
from libCRS.otel import install_otel_logger
from sarif.context import SarifEnv, SarifServerManager
from sarif.models import CP, Harness
from sarif.sarif_model import (
    AixccEnhancedStaticAnalysisResultsFormatSarifVersion210JsonSchema as AIxCCSarif,
)
from sarif.validator.preprocess.info_extraction import validate_code_location
from sarif.validator.reachability.base import BaseReachabilityAnalyser
from sarif.validator.reachability.codeql import CodeQLReachabilityAnalyser

logger = logging.getLogger(__name__)

POLLING_INTERVAL = 1


async def _wait_for_joern_build(build_shared_dir: Path):
    logger.info("Waiting for Joern build")

    done_file = build_shared_dir / "ESSENTIAL_DONE"
    wait_time = 0
    while not done_file.exists():
        await asyncio.sleep(POLLING_INTERVAL)
        wait_time += 1
        if wait_time % 300 == 0:
            logger.info(
                f"Still waiting for joern build... ({wait_time/60:.1f} minutes elapsed)"
            )

    logger.info("Joern build done")


async def _wait_for_codeql_build(build_shared_dir: Path):
    logger.info("Waiting for CodeQL build")

    done_file = build_shared_dir / "CODEQL_DONE"
    wait_time = 0
    while not done_file.exists():
        await asyncio.sleep(POLLING_INTERVAL)
        wait_time += 1
        if wait_time % 300 == 0:
            logger.info(
                f"Still waiting for CodeQL build... ({wait_time/60:.1f} minutes elapsed)"
            )

    logger.info("CodeQL build done")


async def _wait_for_aux_sarif_build(build_shared_dir: Path):
    logger.info("Waiting for aux build")

    done_file = build_shared_dir / "AUX_DONE"
    fail_file = build_shared_dir / "AUX_FAILED"
    wait_time = 0
    while not done_file.exists() and not fail_file.exists():
        await asyncio.sleep(POLLING_INTERVAL)
        wait_time += 1
        if wait_time % 300 == 0:
            logger.info(
                f"Still waiting for aux SARIF build... ({wait_time/60:.1f} minutes elapsed)"
            )

    logger.info("Aux SARIF build done")


def _parse_cpmeta_harness_key(
    cpmeta_dicts: list[dict],
) -> list[str]:
    hanress_in_cpmeta_set = set()

    for cpmeta_dict in cpmeta_dicts:
        harness = cpmeta_dict["harnesses"]

        for name in harness.keys():
            hanress_in_cpmeta_set.add(name)

    return list(hanress_in_cpmeta_set)


def _check_complete_cpmeta(cpmeta_parent_path: Path) -> bool:
    cpmeta_files = list(cpmeta_parent_path.glob("cpmeta*.json"))
    cpmeta_dicts = []
    for cpmeta_file in cpmeta_files:
        cpmeta_dicts.append(json.load(open(cpmeta_file)))

    if set(_parse_cpmeta_harness_key(cpmeta_dicts)) != set(
        CRSEnv().cp.harnesses.keys()
    ):
        return False

    return True


async def _wait_for_cpmeta(cpmeta_parent_path: Path, timeout=300):
    logger.info("Waiting for cpmeta")

    wait_time = 0
    while True:
        if _check_complete_cpmeta(cpmeta_parent_path):
            break

        await asyncio.sleep(60)
        wait_time += 60
        if wait_time % 300 == 0:
            logger.info(
                f"Still waiting for cpmeta... ({wait_time/60:.1f} minutes elapsed)"
            )

        if wait_time > timeout:
            logger.warning("Timeout waiting for cpmeta. Use only partial cpmeta files.")
            break

    logger.info("cpmeta done")


async def _wait_for_poc_gen_build(build_shared_dir: Path):
    logger.info("Waiting for poc gen build")

    done_file = build_shared_dir / "POC_GEN_DONE"
    fail_file = build_shared_dir / "POC_GEN_FAILED"
    wait_time = 0
    while not done_file.exists() and not fail_file.exists():
        await asyncio.sleep(POLLING_INTERVAL)
        wait_time += 1
        if wait_time % 300 == 0:
            logger.info(
                f"Still waiting for poc gen build... ({wait_time/60:.1f} minutes elapsed)"
            )

    logger.info("Poc gen build done")


async def init_aux_analyser():
    logger.info("Initializing aux analyser")

    await _wait_for_aux_sarif_build(CRSEnv().build_shared_dir)

    if CRSEnv().project_language in ["jvm", "java"]:
        await _wait_for_cpmeta(CRSEnv().java_cp_metadata_path)
        cpmeta_files = list(CRSEnv().java_cp_metadata_path.glob("cpmeta*.json"))
        if len(cpmeta_files) > 0:
            SarifEnv().cpmeta_paths = cpmeta_files
            SarifEnv().cpmeta_dicts = [
                json.load(open(cpmeta_file)) for cpmeta_file in cpmeta_files
            ]
        else:
            logger.warning("No cpmeta files found. Do not use Sootup for this project.")

    if (
        CRSEnv().project_language in ["c", "cpp", "c++"]
        and (CRSEnv().build_shared_dir / "AUX_FAILED").exists()
    ):
        logger.warning("Aux build failed. Do not use SVF for this project.")
        return

    if CRSEnv().project_language in ["jvm", "java"] and (
        SarifEnv().cpmeta_paths is None or len(SarifEnv().cpmeta_paths) == 0
    ):
        logger.warning("No cpmeta files found. Do not use Sootup for this project.")
        return

    await CRSDirSetting._download_aux_build_shared_dir()

    analyser_service = AnalyserService()

    if len(analyser_service.aux_analysers) > 0:
        await analyser_service.init_aux_callgraphs()
        await analyser_service.merge_aux_callgraphs()
        await analyser_service.dump_reachability_results()
        await analyser_service.update_analysis_results()


async def init_joern():
    logger.info("Initializing joern")

    await _wait_for_joern_build(CRSEnv().build_shared_dir)

    if (CRSEnv().build_shared_dir / "JOERN_CPG_FAILED").exists():
        logger.warning("Joern build failed. Do not use Joern for this project.")
        return

    await CRSDirSetting._download_joern_build_shared_dir()

    # Init Joern server
    SarifServerManager()

    logger.info("Joern server initialized")


async def init_analyser():
    logger.info("Initializing analyser")

    await _wait_for_codeql_build(CRSEnv().build_shared_dir)

    await CRSDirSetting._download_codeql_build_shared_dir()

    # Update harness abs path
    await CRSEnv().update_sarif_harness_paths_codeql()

    # Intialize reachability analysers
    analyser_service = AnalyserService()

    # Save initial static reachability results and sarif analysis results
    try:
        await analyser_service.init_callgraphs()
        await analyser_service.dump_reachability_results()
        await analyser_service.update_analysis_results()
    except Exception as e:
        logger.exception(f"Error initializing analyser: {e}")
        logger.info("Retrying analyser initialization... After 30 seconds")
        await asyncio.sleep(30)
        await analyser_service.init_callgraphs()
        await analyser_service.dump_reachability_results()
        await analyser_service.update_analysis_results()

    # Start tasks (dynamic call graph update)
    await analyser_service.start_tasks()

    CRSEnv().analyser_init_done = True

    logger.info("Analyser initialized")

    if CRSEnv().project_language in ["c", "cpp", "c++"]:
        asyncio.create_task(init_llm_poc_gen())

    asyncio.create_task(init_aux_analyser())


async def init_llm_poc_gen():
    logger.info("Initializing llm-poc-gen")

    await _wait_for_poc_gen_build(CRSEnv().build_shared_dir)

    if CRSEnv().project_language in ["c", "cpp", "c++"] and (
        (CRSEnv().build_shared_dir / "JOERN_CPG_FAILED").exists()
        or (CRSEnv().build_shared_dir / "POC_GEN_FAILED").exists()
    ):
        logger.warning(
            "llm-poc-gen build failed. Do not use llm-poc-gen for this project."
        )
        return

    await CRSDirSetting._download_poc_gen_build_shared_dir()

    CRSEnv().llm_poc_gen_init_done = True

    logger.info("llm-poc-gen initialized")

    sarif_match_requests = RedisUtil().get_all_sarif_match_requests()
    for sarif_match_request in sarif_match_requests:
        logger.info(
            f"Running blobgen for sarif match request: sarif_id={sarif_match_request.sarif_id}"
        )
        await blobgen(sarif_match_request.sarif, sarif_match_request.sarif_id)


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Initialize services
    install_otel_logger(action_name="crs-sarif")

    # Intialize context
    CRSEnv()
    cp = CP(
        name=CRSEnv().project_name,
        language=(
            "java" if CRSEnv().project_language == "jvm" else CRSEnv().project_language
        ),
        oss_fuzz_lang=CRSEnv().project_language,
        harnesses=[
            Harness(
                name=harness.name,
                path=harness.src_path,
            )
            for harness in CRSEnv().cp.harnesses.values()
        ],
    )
    logger.info(f"CP: {cp.model_dump_json()}")
    SarifEnv(cp=cp, env_mode="crs", debug_mode="release")

    # Initialize API and DB
    VapiClient()
    RedisUtil()

    # Initialize analyser
    asyncio.create_task(init_analyser())
    asyncio.create_task(init_joern())

    yield
    # Cleanup services
    # await analyser_service.stop_tasks()


app = FastAPI(
    title="SARIF System API",
    version="1.0.0",
    lifespan=lifespan,
)


@app.post(
    "/match/patch/",
    response_model=None,
    responses={"400": {"model": Error}, "500": {"model": Error}},
)
async def post_match_patch_(body: PatchMatchRequest = None) -> typing.Optional[Error]:
    """
    Request Patch-SARIF match
    """
    asyncio.create_task(match_patch(body))

    return JSONResponse(
        status_code=200, content={"message": "patch to sarif match started"}
    )


@app.post(
    "/match/pov/",
    response_model=None,
    responses={"400": {"model": Error}, "500": {"model": Error}},
)
async def post_match_pov_(body: POVMatchRequest = None) -> JSONResponse:
    """
    Request POV-SARIF match
    """
    asyncio.create_task(match_pov(body))

    return JSONResponse(
        status_code=200, content={"message": "pov to sarif match started"}
    )


@app.post(
    "/match/sarif/",
    response_model=None,
    responses={"400": {"model": Error}, "500": {"model": Error}},
)
async def post_match_sarif_(body: SARIFMatchRequest = None) -> JSONResponse:
    """
    Request POV-SARIF match
    """
    # Wrong format
    try:
        sarif_model = AIxCCSarif.model_validate(body.sarif)
    except ValidationError as e:
        logger.exception(f"Error validating sarif: {e}")
        VapiClient().submit_sarif(
            assessment=TypesAssessment.INCORRECT,
            sarif_id=str(body.sarif_id),
            pov_id=None,
            description="Invalid SARIF format",
        )
        logger.info(
            f"Submit sarif as incorrect due to wrong format, sarif_id={body.sarif_id}"
        )
        return JSONResponse(
            status_code=400, content={"message": "Invalid SARIF format"}
        )

    # Wrong code location
    if not validate_code_location(
        sarif_model, CRSEnv().cp_src_path, CRSEnv().compiled_src_dir
    ):
        VapiClient().submit_sarif(
            assessment=TypesAssessment.INCORRECT,
            sarif_id=str(body.sarif_id),
            pov_id=None,
            description="Invalid code location",
        )
        logger.info(
            f"Submit sarif as incorrect due to wrong code location, sarif_id={body.sarif_id}"
        )
        return JSONResponse(
            status_code=400, content={"message": "Invalid code location"}
        )

    if CRSEnv().project_language in ["c", "cpp", "c++"]:
        asyncio.create_task(blobgen(body.sarif, body.sarif_id))

    asyncio.create_task(match_sarif(body))

    return JSONResponse(
        status_code=200, content={"message": "sarif to pov match started"}
    )


@app.post(
    "/match/pov-sarif/",
    response_model=PoVSarifMatchResponse,
    responses={"400": {"model": Error}, "500": {"model": Error}},
)
async def post_match_pov_sarif_(
    body: PoVSarifMatchRequest = None,
) -> typing.Union[PoVSarifMatchResponse, Error]:
    """
    Request single PoV-SARIF pair match
    """

    with RedisUtil().redis.lock(
        f"pov-sarif-match-request-{body.pov_match_request.pov_id}-{body.sarif_match_request.sarif_id}-lock"
    ):
        response = RedisUtil().get_pov_sarif_match_request(
            body.pov_match_request.pov_id, body.sarif_match_request.sarif_id
        )
        if response is None:
            RedisUtil().set_pov_sarif_match_request(
                body.pov_match_request.pov_id,
                body.sarif_match_request.sarif_id,
                PoVSarifMatchResponse.pending,
            )
        else:
            return response

    asyncio.create_task(match_pov_sarif(body))

    return PoVSarifMatchResponse.pending


@app.post(
    "/match/pov-patch-sarif/",
    response_model=PoVPatchSarifMatchResponse,
    responses={"400": {"model": Error}, "500": {"model": Error}},
)
async def post_match_pov_patch_sarif_(
    body: PoVPatchSarifMatchRequest = None,
) -> typing.Union[PoVPatchSarifMatchResponse, Error]:
    """
    Request single PoV-Patch-SARIF pair match
    """

    with RedisUtil().redis.lock(
        f"pov-patch-sarif-match-request-{body.pov_match_request.pov_id}-{body.patch_match_request.patch_id}-{body.sarif_match_request.sarif_id}-lock"
    ):
        response = RedisUtil().get_pov_patch_sarif_match_request(
            body.pov_match_request.pov_id,
            body.patch_match_request.patch_id,
            body.sarif_match_request.sarif_id,
        )
        if response is None:
            RedisUtil().set_pov_patch_sarif_match_request(
                body.pov_match_request.pov_id,
                body.patch_match_request.patch_id,
                body.sarif_match_request.sarif_id,
                PoVPatchSarifMatchResponse.pending,
            )
        else:
            return response

    asyncio.create_task(match_pov_patch_sarif(body))

    return PoVPatchSarifMatchResponse.pending
